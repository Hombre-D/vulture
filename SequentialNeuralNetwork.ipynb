{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dac8888",
   "metadata": {},
   "source": [
    "https://realpython.com/python-keras-text-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18f9c322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('preprocessed_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "736eec8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(min_df=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(min_df=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(min_df=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=0, tokenizer=None, preprocessor=None)\n",
    "vectorizer.fit(df['tokenized_functions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb35c314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(df['tokenized_functions']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "593964c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "functions = df['tokenized_functions'].values\n",
    "y = df['isVulnerable'].values\n",
    "\n",
    "functions_train, functions_test, y_train, y_test = train_test_split(functions, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "669d8e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=0, tokenizer=None, preprocessor=None)\n",
    "vectorizer.fit(functions_train)\n",
    "\n",
    "X_train = vectorizer.transform(functions_train)\n",
    "X_test = vectorizer.transform(functions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89c0c8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<19595x53113 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 914957 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d40517ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 11:28:47.667395: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-30 11:28:47.694913: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-30 11:28:47.695272: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 11:28:48.302573: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53113\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "print(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a02e36b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32ad57fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 10)                531140    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 531,151\n",
      "Trainable params: 531,151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44024186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 11:33:21.759158: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype variant and shape [19595,3]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-04-30 11:33:21.759533: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [19595]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1959/1960 [============================>.] - ETA: 0s - loss: 0.6967 - accuracy: 0.4979"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 11:33:33.590769: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [4899]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960/1960 [==============================] - 13s 6ms/step - loss: 0.6967 - accuracy: 0.4979 - val_loss: 0.6926 - val_accuracy: 0.4962\n",
      "Epoch 2/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.6914 - accuracy: 0.5039 - val_loss: 0.6926 - val_accuracy: 0.5038\n",
      "Epoch 3/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.6892 - accuracy: 0.5120 - val_loss: 0.6912 - val_accuracy: 0.4987\n",
      "Epoch 4/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.6859 - accuracy: 0.5167 - val_loss: 0.6898 - val_accuracy: 0.5011\n",
      "Epoch 5/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.6806 - accuracy: 0.5254 - val_loss: 0.6894 - val_accuracy: 0.5003\n",
      "Epoch 6/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.6757 - accuracy: 0.5310 - val_loss: 0.6895 - val_accuracy: 0.5038\n",
      "Epoch 7/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.6696 - accuracy: 0.5391 - val_loss: 0.6918 - val_accuracy: 0.4968\n",
      "Epoch 8/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.6632 - accuracy: 0.5576 - val_loss: 0.6931 - val_accuracy: 0.4954\n",
      "Epoch 9/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.6532 - accuracy: 0.5738 - val_loss: 0.7002 - val_accuracy: 0.5166\n",
      "Epoch 10/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.6413 - accuracy: 0.5915 - val_loss: 0.7007 - val_accuracy: 0.5309\n",
      "Epoch 11/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.6235 - accuracy: 0.6054 - val_loss: 0.7205 - val_accuracy: 0.5291\n",
      "Epoch 12/100\n",
      "1960/1960 [==============================] - 11s 5ms/step - loss: 0.6089 - accuracy: 0.6128 - val_loss: 0.7145 - val_accuracy: 0.5579\n",
      "Epoch 13/100\n",
      "1960/1960 [==============================] - 10s 5ms/step - loss: 0.5918 - accuracy: 0.6230 - val_loss: 0.7250 - val_accuracy: 0.5658\n",
      "Epoch 14/100\n",
      "1960/1960 [==============================] - 10s 5ms/step - loss: 0.5786 - accuracy: 0.6295 - val_loss: 0.7300 - val_accuracy: 0.5724\n",
      "Epoch 15/100\n",
      "1960/1960 [==============================] - 11s 5ms/step - loss: 0.5692 - accuracy: 0.6341 - val_loss: 0.7390 - val_accuracy: 0.5766\n",
      "Epoch 16/100\n",
      "1960/1960 [==============================] - 11s 5ms/step - loss: 0.5609 - accuracy: 0.6364 - val_loss: 0.7569 - val_accuracy: 0.5773\n",
      "Epoch 17/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5553 - accuracy: 0.6390 - val_loss: 0.7658 - val_accuracy: 0.5873\n",
      "Epoch 18/100\n",
      "1960/1960 [==============================] - 11s 5ms/step - loss: 0.5510 - accuracy: 0.6429 - val_loss: 0.7737 - val_accuracy: 0.5867\n",
      "Epoch 19/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5472 - accuracy: 0.6430 - val_loss: 0.7881 - val_accuracy: 0.5895\n",
      "Epoch 20/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5430 - accuracy: 0.6449 - val_loss: 0.7886 - val_accuracy: 0.5928\n",
      "Epoch 21/100\n",
      "1960/1960 [==============================] - 11s 5ms/step - loss: 0.5419 - accuracy: 0.6435 - val_loss: 0.7918 - val_accuracy: 0.5928\n",
      "Epoch 22/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5365 - accuracy: 0.6453 - val_loss: 0.8049 - val_accuracy: 0.5960\n",
      "Epoch 23/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5360 - accuracy: 0.6454 - val_loss: 0.8113 - val_accuracy: 0.5950\n",
      "Epoch 24/100\n",
      "1960/1960 [==============================] - 13s 7ms/step - loss: 0.5330 - accuracy: 0.6462 - val_loss: 0.8195 - val_accuracy: 0.5989\n",
      "Epoch 25/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5312 - accuracy: 0.6484 - val_loss: 0.8310 - val_accuracy: 0.5979\n",
      "Epoch 26/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5314 - accuracy: 0.6473 - val_loss: 0.8335 - val_accuracy: 0.5975\n",
      "Epoch 27/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5301 - accuracy: 0.6481 - val_loss: 0.8227 - val_accuracy: 0.6028\n",
      "Epoch 28/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5289 - accuracy: 0.6482 - val_loss: 0.8431 - val_accuracy: 0.5985\n",
      "Epoch 29/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5294 - accuracy: 0.6479 - val_loss: 0.8300 - val_accuracy: 0.6038\n",
      "Epoch 30/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5280 - accuracy: 0.6490 - val_loss: 0.8350 - val_accuracy: 0.6034\n",
      "Epoch 31/100\n",
      "1960/1960 [==============================] - 13s 6ms/step - loss: 0.5247 - accuracy: 0.6492 - val_loss: 0.8487 - val_accuracy: 0.6009\n",
      "Epoch 32/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5246 - accuracy: 0.6490 - val_loss: 0.8452 - val_accuracy: 0.6018\n",
      "Epoch 33/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5253 - accuracy: 0.6476 - val_loss: 0.8402 - val_accuracy: 0.6036\n",
      "Epoch 34/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5259 - accuracy: 0.6488 - val_loss: 0.8403 - val_accuracy: 0.6036\n",
      "Epoch 35/100\n",
      "1960/1960 [==============================] - 13s 7ms/step - loss: 0.5248 - accuracy: 0.6484 - val_loss: 0.8433 - val_accuracy: 0.6020\n",
      "Epoch 36/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5258 - accuracy: 0.6491 - val_loss: 0.8515 - val_accuracy: 0.6024\n",
      "Epoch 37/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5246 - accuracy: 0.6484 - val_loss: 0.8570 - val_accuracy: 0.6009\n",
      "Epoch 38/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5248 - accuracy: 0.6484 - val_loss: 0.8441 - val_accuracy: 0.6032\n",
      "Epoch 39/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5240 - accuracy: 0.6495 - val_loss: 0.8411 - val_accuracy: 0.6036\n",
      "Epoch 40/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5229 - accuracy: 0.6489 - val_loss: 0.8526 - val_accuracy: 0.6050\n",
      "Epoch 41/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5256 - accuracy: 0.6488 - val_loss: 0.8552 - val_accuracy: 0.6024\n",
      "Epoch 42/100\n",
      "1960/1960 [==============================] - 10s 5ms/step - loss: 0.5225 - accuracy: 0.6486 - val_loss: 0.8668 - val_accuracy: 0.6032\n",
      "Epoch 43/100\n",
      "1960/1960 [==============================] - 11s 5ms/step - loss: 0.5258 - accuracy: 0.6489 - val_loss: 0.8486 - val_accuracy: 0.6030\n",
      "Epoch 44/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5251 - accuracy: 0.6486 - val_loss: 0.8529 - val_accuracy: 0.6036\n",
      "Epoch 45/100\n",
      "1960/1960 [==============================] - 11s 5ms/step - loss: 0.5268 - accuracy: 0.6488 - val_loss: 0.8502 - val_accuracy: 0.6028\n",
      "Epoch 46/100\n",
      "1960/1960 [==============================] - 10s 5ms/step - loss: 0.5249 - accuracy: 0.6485 - val_loss: 0.8584 - val_accuracy: 0.6018\n",
      "Epoch 47/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5233 - accuracy: 0.6483 - val_loss: 0.8543 - val_accuracy: 0.6028\n",
      "Epoch 48/100\n",
      "1960/1960 [==============================] - 10s 5ms/step - loss: 0.5228 - accuracy: 0.6488 - val_loss: 0.8527 - val_accuracy: 0.6028\n",
      "Epoch 49/100\n",
      "1960/1960 [==============================] - 11s 5ms/step - loss: 0.5223 - accuracy: 0.6490 - val_loss: 0.8603 - val_accuracy: 0.6018\n",
      "Epoch 50/100\n",
      "1960/1960 [==============================] - 11s 5ms/step - loss: 0.5226 - accuracy: 0.6488 - val_loss: 0.8588 - val_accuracy: 0.6028\n",
      "Epoch 51/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5225 - accuracy: 0.6498 - val_loss: 0.8711 - val_accuracy: 0.6022\n",
      "Epoch 52/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5267 - accuracy: 0.6491 - val_loss: 0.8572 - val_accuracy: 0.6032\n",
      "Epoch 53/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5224 - accuracy: 0.6493 - val_loss: 0.8684 - val_accuracy: 0.6046\n",
      "Epoch 54/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5231 - accuracy: 0.6494 - val_loss: 0.8583 - val_accuracy: 0.6040\n",
      "Epoch 55/100\n",
      "1960/1960 [==============================] - 10s 5ms/step - loss: 0.5213 - accuracy: 0.6492 - val_loss: 0.8736 - val_accuracy: 0.6058\n",
      "Epoch 56/100\n",
      "1960/1960 [==============================] - 11s 5ms/step - loss: 0.5211 - accuracy: 0.6500 - val_loss: 0.8709 - val_accuracy: 0.6042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5223 - accuracy: 0.6490 - val_loss: 0.8727 - val_accuracy: 0.6044\n",
      "Epoch 58/100\n",
      "1960/1960 [==============================] - 11s 5ms/step - loss: 0.5216 - accuracy: 0.6493 - val_loss: 0.8833 - val_accuracy: 0.6046\n",
      "Epoch 59/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5223 - accuracy: 0.6495 - val_loss: 0.8667 - val_accuracy: 0.6054\n",
      "Epoch 60/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5228 - accuracy: 0.6495 - val_loss: 0.8496 - val_accuracy: 0.6058\n",
      "Epoch 61/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5197 - accuracy: 0.6496 - val_loss: 0.8727 - val_accuracy: 0.6034\n",
      "Epoch 62/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5227 - accuracy: 0.6498 - val_loss: 0.8734 - val_accuracy: 0.6044\n",
      "Epoch 63/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5199 - accuracy: 0.6499 - val_loss: 0.8660 - val_accuracy: 0.6056\n",
      "Epoch 64/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5247 - accuracy: 0.6496 - val_loss: 0.8677 - val_accuracy: 0.6050\n",
      "Epoch 65/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5228 - accuracy: 0.6504 - val_loss: 0.8716 - val_accuracy: 0.6046\n",
      "Epoch 66/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5235 - accuracy: 0.6500 - val_loss: 0.8681 - val_accuracy: 0.6024\n",
      "Epoch 67/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5221 - accuracy: 0.6498 - val_loss: 0.8654 - val_accuracy: 0.6042\n",
      "Epoch 68/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5221 - accuracy: 0.6503 - val_loss: 0.8667 - val_accuracy: 0.6042\n",
      "Epoch 69/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5224 - accuracy: 0.6503 - val_loss: 0.8738 - val_accuracy: 0.6038\n",
      "Epoch 70/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5213 - accuracy: 0.6508 - val_loss: 0.8746 - val_accuracy: 0.6042\n",
      "Epoch 71/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5203 - accuracy: 0.6507 - val_loss: 0.8762 - val_accuracy: 0.6030\n",
      "Epoch 72/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5218 - accuracy: 0.6508 - val_loss: 0.8729 - val_accuracy: 0.6044\n",
      "Epoch 73/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5191 - accuracy: 0.6510 - val_loss: 0.8755 - val_accuracy: 0.6042\n",
      "Epoch 74/100\n",
      "1960/1960 [==============================] - 10s 5ms/step - loss: 0.5198 - accuracy: 0.6509 - val_loss: 0.8882 - val_accuracy: 0.6040\n",
      "Epoch 75/100\n",
      "1960/1960 [==============================] - 10s 5ms/step - loss: 0.5225 - accuracy: 0.6514 - val_loss: 0.8889 - val_accuracy: 0.6046\n",
      "Epoch 76/100\n",
      "1960/1960 [==============================] - 10s 5ms/step - loss: 0.5218 - accuracy: 0.6505 - val_loss: 0.8594 - val_accuracy: 0.6052\n",
      "Epoch 77/100\n",
      "1960/1960 [==============================] - 11s 5ms/step - loss: 0.5197 - accuracy: 0.6505 - val_loss: 0.8662 - val_accuracy: 0.6046\n",
      "Epoch 78/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5219 - accuracy: 0.6507 - val_loss: 0.8648 - val_accuracy: 0.6026\n",
      "Epoch 79/100\n",
      "1960/1960 [==============================] - 11s 5ms/step - loss: 0.5187 - accuracy: 0.6507 - val_loss: 0.8575 - val_accuracy: 0.6065\n",
      "Epoch 80/100\n",
      "1960/1960 [==============================] - 10s 5ms/step - loss: 0.5207 - accuracy: 0.6506 - val_loss: 0.8666 - val_accuracy: 0.6048\n",
      "Epoch 81/100\n",
      "1960/1960 [==============================] - 11s 5ms/step - loss: 0.5198 - accuracy: 0.6509 - val_loss: 0.8682 - val_accuracy: 0.6048\n",
      "Epoch 82/100\n",
      "1960/1960 [==============================] - 10s 5ms/step - loss: 0.5197 - accuracy: 0.6504 - val_loss: 0.8817 - val_accuracy: 0.6056\n",
      "Epoch 83/100\n",
      "1960/1960 [==============================] - 11s 5ms/step - loss: 0.5203 - accuracy: 0.6507 - val_loss: 0.8681 - val_accuracy: 0.6060\n",
      "Epoch 84/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5218 - accuracy: 0.6508 - val_loss: 0.8678 - val_accuracy: 0.6062\n",
      "Epoch 85/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5184 - accuracy: 0.6505 - val_loss: 0.8564 - val_accuracy: 0.6073\n",
      "Epoch 86/100\n",
      "1960/1960 [==============================] - 11s 5ms/step - loss: 0.5209 - accuracy: 0.6507 - val_loss: 0.8492 - val_accuracy: 0.6077\n",
      "Epoch 87/100\n",
      "1960/1960 [==============================] - 10s 5ms/step - loss: 0.5212 - accuracy: 0.6510 - val_loss: 0.8788 - val_accuracy: 0.6065\n",
      "Epoch 88/100\n",
      "1960/1960 [==============================] - 10s 5ms/step - loss: 0.5253 - accuracy: 0.6514 - val_loss: 0.8798 - val_accuracy: 0.6069\n",
      "Epoch 89/100\n",
      "1960/1960 [==============================] - 11s 5ms/step - loss: 0.5226 - accuracy: 0.6512 - val_loss: 0.8634 - val_accuracy: 0.6065\n",
      "Epoch 90/100\n",
      "1960/1960 [==============================] - 11s 5ms/step - loss: 0.5202 - accuracy: 0.6516 - val_loss: 0.8625 - val_accuracy: 0.6071\n",
      "Epoch 91/100\n",
      "1960/1960 [==============================] - 10s 5ms/step - loss: 0.5200 - accuracy: 0.6514 - val_loss: 0.8716 - val_accuracy: 0.6056\n",
      "Epoch 92/100\n",
      "1960/1960 [==============================] - 10s 5ms/step - loss: 0.5195 - accuracy: 0.6513 - val_loss: 0.8701 - val_accuracy: 0.6062\n",
      "Epoch 93/100\n",
      "1960/1960 [==============================] - 10s 5ms/step - loss: 0.5213 - accuracy: 0.6514 - val_loss: 0.8702 - val_accuracy: 0.6062\n",
      "Epoch 94/100\n",
      "1960/1960 [==============================] - 10s 5ms/step - loss: 0.5189 - accuracy: 0.6517 - val_loss: 0.8986 - val_accuracy: 0.6040\n",
      "Epoch 95/100\n",
      "1960/1960 [==============================] - 10s 5ms/step - loss: 0.5189 - accuracy: 0.6517 - val_loss: 0.8771 - val_accuracy: 0.6060\n",
      "Epoch 96/100\n",
      "1960/1960 [==============================] - 10s 5ms/step - loss: 0.5228 - accuracy: 0.6515 - val_loss: 0.8576 - val_accuracy: 0.6067\n",
      "Epoch 97/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5193 - accuracy: 0.6515 - val_loss: 0.8728 - val_accuracy: 0.6067\n",
      "Epoch 98/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5201 - accuracy: 0.6516 - val_loss: 0.8710 - val_accuracy: 0.6071\n",
      "Epoch 99/100\n",
      "1960/1960 [==============================] - 12s 6ms/step - loss: 0.5175 - accuracy: 0.6515 - val_loss: 0.8822 - val_accuracy: 0.6067\n",
      "Epoch 100/100\n",
      "1960/1960 [==============================] - 11s 6ms/step - loss: 0.5186 - accuracy: 0.6520 - val_loss: 0.8810 - val_accuracy: 0.6073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 11:51:56.307144: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [19595]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.6527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 11:51:56.914754: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype int64 and shape [4899]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.6073\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, verbose=True, validation_data=(X_test, y_test), batch_size=10)\n",
    "from keras.backend import clear_session\n",
    "clear_session()\n",
    "\n",
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec84572",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
