{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78e946a8",
   "metadata": {},
   "source": [
    "Convolutional Neural Network\n",
    "https://realpython.com/python-keras-text-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d4d322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('preprocessed_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c1c6a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "functions = df['function'].values\n",
    "y = df['isVulnerable'].values\n",
    "\n",
    "functions_train, functions_test, y_train, y_test = train_test_split(functions, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "906d36c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-30 13:00:06.841169: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-30 13:00:06.878944: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-30 13:00:06.879388: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-30 13:00:07.491103: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "\n",
    "tokenizer = Tokenizer(analyzer=wordpunct_tokenize)\n",
    "tokenizer.fit_on_texts(functions_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(functions_train)\n",
    "X_test = tokenizer.texts_to_sequences(functions_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51d15b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54797\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac4110c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   41 37081     1    10    91    12    91     4   122    12  1966     7\n",
      "     9    10  7691    12   538     6  1731    91     2  5138     5   382\n",
      "    14   538     2   101     5     8     1   538     2 17660     7     9\n",
      "   538     2 37082     6    15     3    86     1   538     2 17660     5\n",
      "   538     2 17660     6    35     3    11     8     1  2359     1   538\n",
      "     4 13530    28     9   555    14   538     2 23429     5  4799     1\n",
      "   538     4 13530     5    11 37083    14    91     2  8529     5     8\n",
      "     1   538     2 13882     7     9     8   108  2359     1   538     4\n",
      " 25100     7    38   115    28     9     8     1  2359     1   538     4\n",
      "  5431     7    38   118     7     9 25101     1   538     4  3686     5\n",
      "     8     1 13531     1   538     7    38  4094     7     9  6394    14\n",
      "   538     2  4800     4 13532     5    11    48     9   122    19     6\n",
      "  4094     3    10 15441    12 25102     6  1731    91     2 25103    13\n",
      " 25104     5   122    12 25105     6    91     2 25103    13 25104    13\n",
      "  3612     3  4799     1   538     4 13530     5   247    14 25102     2\n",
      "  2575     4    18   538     2 25106     4    50     1    10 37084    52\n",
      " 37085     1    91     5 37086     1 25105     5   538     2 21462     6\n",
      " 25107     3   538     2 13882     6   118     3    19     6 37087     1\n",
      "    91     5     8     1    19    62  4094     7    27   589     3    11\n",
      "    11    11    48     9    20 13883     3 25101     1   538     4  3686\n",
      "     5   538     2 13882     6   118     3 13883     6 13531     1   538\n",
      "     5     8     1  4094    38 13883     7     9  6394    14   538     2\n",
      "  4800     4 13532     5    11    48     8     1 13883    38    99     7\n",
      " 10509  8779   311   393  4176    75   541    64  8530    58  4799     1\n",
      "   538     4  3686     5 10199     1    91     5    11    48     9     8\n",
      "     1 21463     1    91     7    62    15     7     9     8     1 27587\n",
      "     1    91     7    38    15    65  4094    62 37088     1    91     4\n",
      "    18   538     2 25106     4    32     4    35     4    15     7     7\n",
      "     9 37089     1    91     4    15     5 25108     1    91     4    32\n",
      "     5 13884     1    91     5    11    48     9   538     2 13882     6\n",
      "   115     3    11    11    48 13884     1    91     5  4799     1   538\n",
      "     4  3686     5    11    11    11    48     9     8     1 37090     1\n",
      "    91     4 37091    28     9     8     1  2359     1   538     4  4971\n",
      "     7    51  2359     1   538     4  5431    28     9     8     1 37092\n",
      "     1   538     7    38  4094     7     9 37093     1    91     4   538\n",
      "     2  3527    13  1851    13  3612     4 37094     5    11    11    11\n",
      "    11   589    22   331    14   538     2   101     5 37095     1    91\n",
      "     5 37096     1    91     5 23430     1    91     4   118     5    11\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import pad_sequences\n",
    "\n",
    "maxlen = 1000\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2abcbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1000, 100)         5479700   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 996, 128)          64128     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1290      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,545,129\n",
      "Trainable params: 5,545,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "embedding_dim=100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af7a94c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1960/1960 [==============================] - 169s 86ms/step - loss: 0.6672 - accuracy: 0.5446 - val_loss: 0.6307 - val_accuracy: 0.5905\n",
      "Epoch 2/10\n",
      "1960/1960 [==============================] - 159s 81ms/step - loss: 0.5840 - accuracy: 0.6189 - val_loss: 0.5660 - val_accuracy: 0.6150\n",
      "Epoch 3/10\n",
      "1960/1960 [==============================] - 160s 81ms/step - loss: 0.5059 - accuracy: 0.6788 - val_loss: 0.5202 - val_accuracy: 0.6473\n",
      "Epoch 4/10\n",
      "1960/1960 [==============================] - 158s 81ms/step - loss: 0.4547 - accuracy: 0.7078 - val_loss: 0.4893 - val_accuracy: 0.6710\n",
      "Epoch 5/10\n",
      "1960/1960 [==============================] - 161s 82ms/step - loss: 0.4208 - accuracy: 0.7270 - val_loss: 0.4787 - val_accuracy: 0.6881\n",
      "Epoch 6/10\n",
      "1960/1960 [==============================] - 163s 83ms/step - loss: 0.3966 - accuracy: 0.7378 - val_loss: 0.4789 - val_accuracy: 0.6916\n",
      "Epoch 7/10\n",
      "1960/1960 [==============================] - 163s 83ms/step - loss: 0.3838 - accuracy: 0.7432 - val_loss: 0.5273 - val_accuracy: 0.6995\n",
      "Epoch 8/10\n",
      "1960/1960 [==============================] - 162s 83ms/step - loss: 0.3748 - accuracy: 0.7469 - val_loss: 0.4774 - val_accuracy: 0.7022\n",
      "Epoch 9/10\n",
      "1960/1960 [==============================] - 163s 83ms/step - loss: 0.3667 - accuracy: 0.7493 - val_loss: 0.5122 - val_accuracy: 0.7010\n",
      "Epoch 10/10\n",
      "1960/1960 [==============================] - 164s 84ms/step - loss: 0.3633 - accuracy: 0.7507 - val_loss: 0.5106 - val_accuracy: 0.7040\n",
      "Training Accuracy: 0.7533\n",
      "Testing Accuracy:  0.7040\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plot_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting Accuracy:  \u001b[39m\u001b[38;5;132;01m{:.4f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(accuracy))\n\u001b[0;32m---> 13\u001b[0m \u001b[43mplot_history\u001b[49m(history)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_history' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.backend import clear_session\n",
    "clear_session()\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    verbose=True,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=10)\n",
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cf3f35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
